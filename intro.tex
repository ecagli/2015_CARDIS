\section{Introduction}
Reducing the dimensionality of the data is an important issue for Side-Channel Attacks (SCA). The data are typically measurements of power consumption or electromagnetic irradiations occurring unavoidably during the execution of cryptographic algorithms over electronic devices. Such data can reveal enough information about sensitive variables handled during the computations, to let an attacker guess secret data ({\em e.g.} cryptographic keys) stored in the device. The instruments that acquire SC traces are usually oscilloscopes with a very high sampling rate, which permits a powerful inspection of the component behaviour, but, at the same time, produces high-dimensional data, that spread over several time samples the information about interesting sensitive variables, and that need to be compressed to avoid computational processing infeasibility. If we look at SC traces as vectors of $\mathbb{R}^\traceLength$, the compressing phase might be seen as the application of a function $\extract\colon \mathbb{R}^\traceLength\rightarrow \mathbb{R}^\newTraceLength$, called {\em extractor}.\\

In this paper we will focus on the so-called {\em Projecting Extractors}, {\em i.e.} those methods that provide extractors $\extract$ whose image components are linear combinations of the original data, or, equivalently, expressible via a matrix multiplication:
\begin{equation}
\extractor{\sss[]{}} = A\sss[]{} \mbox{ with } A \in M_{\mathbb{R}}(\newTraceLength, \traceLength) \mbox{ ,}
\end{equation}
where $ M_{\mathbb{R}}(\newTraceLength, \traceLength)$ denotes the algebra of real-coefficient matrices of size $\newTraceLength \times \traceLength$.  In particular we effectuate an in depth study and a comprehensive comparison  between the PCA and the LDA methods \cite{fisher1938statistical,Fukunaga}, and their exploitability  in Side-Channel context.  Indeed, PCA and LDA are classical statistical procedures, but the way they have been inherited in SCA domain is somehow ambiguous and opened some issues and questions.\\

 The PCA has been applied both in an {\em unsupervised} way, i.e. on the whole data \cite{Batina2012,karsmakers2009side}, and in a {\em supervised} way, i.e. on traces grouped in classes and averaged \cite{TAprincipal,choudaryefficient,choudary2014efficient,disassembler,Standaert2008}. Another ambiguity in PCA concerns the choice of the components that must be kept after the dimension reduction: as also remarked by Specht et al.  \cite{specht}, some papers declare that the leading components are those that contain almost all the useful information \cite{TAprincipal}, while others propose to discard the leading components \cite{Batina2012}. Specht compared, in a specific attack context, the results obtained by choosing different subsets of consecutive components, starting from some empirically chosen index, and concluded that for their data the optimal result is obtained by selecting a single component, the fourth one (with no real argumentation about this choice). Such a result is obviously very case-specific. Moreover, the possibility of keeping non-consecutive components is not considered. In this paper we propose a new selection methodology, called {\em Cumulative ELV Selection}. It is based on the assumption that the leaking information is spread over a few time samples of each trace. The same assumption is done proposed by Mavroeidis \textit{et al.} \cite{SCAclassProbl}, who also proposed a components selection method. The important difference between their proposal and ours is that we do not discard the information given by the eigenvalues associated to the PCA components.  \\

The introduction of the LDA in SCA literature also made some issues arise: even if declared more meaningful and informative than the PCA method \cite{lessIsMore,Standaert2008}, it is often set aside because of a practical constraint; it is subject to the so-called {\em Small Sample Size problem (SSS)}, i.e. it requires a number of observations (traces) which is higher than the dimension (size) $\traceLength$ of them. In some contexts it might be an excessive requirement, which may become unacceptable in many practical contexts where the amount of observations is very limited. Nevertheless, many propositions to circumvent this problem have been made, especially by Pattern Recognition and Face Recognition communities \cite{eigenfaces,Chen2000,huang,Yu01adirect}. We find mandatory to test and compare such methods in Side-Channel context.\\

The paper is organised as follows: in Section \ref{sec:preliminaries} we fix notations, recall preliminaries and set up a unified comparison framework to compare different extractors. Section \ref{sec:PCA} presents the PCA, and handles the choice of components problem, introducing the  ELV selection method. In Section \ref{sec:LDA} the LDA method is presented, together with different methodologies to avoid the SSS problem. Experiments and comparison are showed in Section \ref{sec:experiments}, while conclusions and perspectives follows in Section \ref{sec:conclusions}. 

