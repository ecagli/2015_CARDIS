\section{Introduction}
The measurement of the power consumption or of the electromagnetic irradiations during the execution of cryptographic algorithms in constrained electronic devices can reveal information about sensitive variables ({\em e.g.} cryptographic keys). The side channel traces are usually acquired by oscilloscopes with a very high sampling rate, which permits a powerful inspection of the component behaviour, but, at the same time, produces high-dimensional data, that spread the sensitive information over a (sometimes) huge number of time samples. Reducing the dimensionality of the data is an important issue for Side-Channel Attacks (SCA). Considering the side channel traces as column vectors ${\bf x}$ in $\mathbb{R}^\traceLength$, the compressing phase might be seen as the application of a function $\extract\colon \mathbb{R}^\traceLength\rightarrow \mathbb{R}^\newTraceLength$, called {\em extractor} in this paper.\\

The present work focuses on the so-called {\em projecting extractors}, {\em i.e.} those methods that provide extractors $\extract$ whose image components are linear combinations of the original data, or equivalently, expressible {\em via} a matrix multiplication:
\begin{equation}\label{eq:linearExtractor}
\extractor{\sss[]{}} = A\sss[]{} \mbox{ with } A \in M_{\mathbb{R}}(\newTraceLength, \traceLength) \mbox{ ,}
\end{equation}
where $ M_{\mathbb{R}}(\newTraceLength, \traceLength)$ denotes the set of real-coefficient matrices of size $\newTraceLength \times \traceLength$.  In particular we effectuate an in-depth study and a comprehensive comparison  between the PCA and the LDA methods \cite{fisher1938statistical,Fukunaga}, and we investigate their exploitability  in Side-Channel context.  Indeed, PCA and LDA are classical statistical procedures, but the way they have been inherited in SCA domain is somehow ambiguous and opened some issues and questions.\\


 The PCA has been applied both in an {\em unsupervised} way, i.e. on the whole data \cite{Batina2012,karsmakers2009side}, and in a {\em supervised} way, i.e. on traces grouped in classes and averaged \cite{TAprincipal,choudaryefficient,choudary2014efficient,disassembler,Standaert2008}. The second way implies that, during the training phase, the attacker is able to choose, or at least to know, the secret parameters of the implementation under attack (or a perfect copy of it). As already remarked in \cite{disassembler} and not surprisingly, the complete knowledge assumed in the supervised approach hugely raises performances; we will highlight it in our experiments, and we will concentrate on this powerful kind of approach, leaving the unsupervised case for further studies. The main competitor of PCA in the supervised context is the LDA, that thanks to its class-distinguishability asset, is known to be more meaningful and informative \cite{lessIsMore,Standaert2008} than the PCA method  for side channels. Nevertheless, the LDA is often set aside because of its practical constraints; it is subject to the so-called {\em Small Sample Size problem (SSS)}, i.e. it requires a number of observations (traces) which must be higher than the dimension (size) $\traceLength$ of them. In some contexts it might be an excessive requirement, which may become unacceptable in many practical situations where the amount of observations is very limited and the traces size is huge.\\

 One of the open issues in PCA concerns the choice of the components that must be kept after the dimension reduction: as already remarked by Specht et al.  \cite{specht}, some papers declare that the leading components are those that contain almost all the useful information \cite{TAprincipal,choudary2014efficient}, while others propose to discard the leading components \cite{Batina2012}. In a specific attack context, Specht et al. compares the results obtained by choosing different subsets of consecutive components, starting from some empirically chosen index. They conclude that for their data the optimal result is obtained by selecting a single component, the fourth one, but they give no formal argumentation about this choice. Such a result is obviously very case-specific. Moreover, the possibility of keeping non-consecutive components is not considered. \\
 
 Our main contribution consists in proposing a new selection methodology, called {\em cumulative ELV selection}. We will argue about the generality and the soundness of this methodology and show that it can raise the PCA performances, making them close to those of the LDA, even in the supervised context. This makes PCA an interesting alternative to LDA in those cases where the LDA is inapplicable. The reasonning behind the ELV selection methodology is essentially based on the observation that, for secure implementations, the leaking information, if existing, is spread over a few time samples of each trace. This observation has already been met by Mavroeidis et al. in \cite{SCAclassProbl}, where the authors  also proposed a components selection method. As we will see in this paper, the main difference between their proposal and ours is that we do not discard the information given by the eigenvalues associated to the PCA components, but we synergistically exploit such information and the observation met. For the sake of comparison, we also analyse many propositions to circumvent the SSS problem that have been made in literature, especially by Pattern Recognition and Face Recognition communities \cite{eigenfaces,Chen2000,huang,Yu01adirect}. The gain given by these techniques does not outperform the PCA method equipped with our ELV selection.\\

The paper is organised as follows: in Section \ref{sec:preliminaries} we fix notations, recall preliminaries and formalize the context. Section \ref{sec:PCA} presents the PCA, and handles the choice of components problem, introducing the  ELV selection method. In Section \ref{sec:LDA} the LDA method is presented, together with different methodologies to avoid the SSS problem. Experiments and comparisons are showed in Section \ref{sec:experiments}, while conclusions and perspectives follow in Section \ref{sec:conclusions}. 